{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PLOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "362279\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "path = \"G:\\\\Dataset\\\\PLOS\\\\allofplos\"\n",
    "filenames = os.listdir(path)\n",
    "\n",
    "print(len(filenames))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.1 熟悉lxml库\n",
    "\n",
    "https://lxml.de/tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import etree\n",
    "\n",
    "def prettyprint(element, **kwargs):\n",
    "    xml = etree.tostring(element, pretty_print=True, **kwargs)\n",
    "    print(xml.decode(), end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = etree.parse(os.path.join(path, filenames[0]))\n",
    "root = tree.getroot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.2 检查所有文件的文件名结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 93/362279 [00:00<06:47, 887.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The structure of journal.pbio.0000091.xml is unstandard\n",
      "The structure of journal.pbio.0000092.xml is unstandard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1001/362279 [00:09<55:06, 109.28it/s] \n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "cnt = 1000\n",
    "\n",
    "section_names = []\n",
    "num_sections = []\n",
    "error_structure_files = []\n",
    "\n",
    "for idx, filename in enumerate(tqdm(filenames)):\n",
    "    if idx > cnt:\n",
    "        break\n",
    "    tree = etree.parse(os.path.join(path, filename))\n",
    "    root = tree.getroot()\n",
    "\n",
    "    xml_structure = {}\n",
    "    for child in root:\n",
    "        xml_structure[child.tag] = child\n",
    "    \n",
    "    body = xml_structure['body']\n",
    "\n",
    "    num_section = len(body)\n",
    "    num_sections.append(num_section)\n",
    "    if num_section > 0:\n",
    "        for sec in body:\n",
    "            try:\n",
    "                title = sec[0]\n",
    "                section_names.append(title.text)\n",
    "            except:\n",
    "                print(\"The structure of {} is unstandard\".format(filename))\n",
    "                error_structure_files.append(filename)\n",
    "                break\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(None, 620),\n",
       " ('Introduction', 391),\n",
       " ('Materials and Methods', 389),\n",
       " ('Results', 327),\n",
       " ('Discussion', 325),\n",
       " ('Supporting Information', 315),\n",
       " ('Results/Discussion', 58),\n",
       " ('\\n        ', 15),\n",
       " ('Conclusions', 9),\n",
       " ('Results and Discussion', 6)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "section_name_dict = {}\n",
    "\n",
    "for name in section_names:\n",
    "    if name in section_name_dict:\n",
    "        section_name_dict[name] += 1\n",
    "    else:\n",
    "        section_name_dict[name] = 1\n",
    "\n",
    "section_name_dict = sorted(section_name_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "section_name_dict[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.3 抽取题录信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1001/362279 [00:10<1:04:28, 93.39it/s]\n"
     ]
    }
   ],
   "source": [
    "# title, abstract, journal, doi\n",
    "\n",
    "metadatas = []\n",
    "\n",
    "for idx, filename in enumerate(tqdm(filenames)):\n",
    "    if idx > 1000:\n",
    "        break\n",
    "\n",
    "    tree = etree.parse(os.path.join(path, filename))\n",
    "    root = tree.getroot()\n",
    "\n",
    "    metadata = {}\n",
    "\n",
    "    dois = root.xpath(\"//article-id[@pub-id-type=\\\"doi\\\"]\")\n",
    "    for doi in dois:\n",
    "        metadata['doi'] = doi.text\n",
    "\n",
    "    journal_titles = root.xpath(\"//journal-meta//journal-title\")\n",
    "    metadata['journal'] = ''\n",
    "    for title in journal_titles:\n",
    "        metadata['journal'] = title.text\n",
    "\n",
    "    paper_titles = root.xpath(\"//article-meta//article-title\")\n",
    "    metadata['title'] = []\n",
    "    for title in paper_titles:\n",
    "        metadata['title'].append(title.text)\n",
    "\n",
    "    abstracts = root.xpath(\"//article-meta//abstract\")\n",
    "    metadata['abstract'] = []\n",
    "    for abstract in abstracts:\n",
    "        metadata['abstract'].append(abstract[0].text)\n",
    "\n",
    "    references = []\n",
    "    refer_list = root.xpath(\"//back//ref\")\n",
    "    for refer in refer_list:\n",
    "        refer_structure = {}\n",
    "        id = refer.attrib['id']\n",
    "        refer_structure['id'] = id\n",
    "        try:\n",
    "            refer_structure['title'] = refer.xpath(\"//ref[@id=\\\"{}\\\"]//article-title\".format(id))[0].text\n",
    "        except:\n",
    "            refer_structure['title'] = ''\n",
    "        try:\n",
    "            refer_structure['source'] = refer.xpath(\"//ref[@id=\\\"{}\\\"]//source\".format(id))[0].text\n",
    "        except:\n",
    "            refer_structure['source'] = ''\n",
    "        try:\n",
    "            refer_structure['year'] = refer.xpath(\"//ref[@id=\\\"{}\\\"]//year\".format(id))[0].text\n",
    "        except:\n",
    "            refer_structure['year'] = ''\n",
    "\n",
    "        references.append(refer_structure)\n",
    "\n",
    "    metadata['num_reference'] = len(references)\n",
    "    metadata['reference'] = references\n",
    "    \n",
    "    metadatas.append(metadata)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.4 抽取参考文献信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "references = []\n",
    "\n",
    "refer_list = root.xpath(\"//back//ref\")\n",
    "\n",
    "for refer in refer_list:\n",
    "    refer_structure = {}\n",
    "    id = refer.attrib['id']\n",
    "    refer_structure['id'] = id\n",
    "    try:\n",
    "        refer_structure['title'] = refer.xpath(\"//ref[@id=\\\"{}\\\"]//article-title\".format(id))[0].text\n",
    "    except:\n",
    "        refer_structure['title'] = ''\n",
    "    try:\n",
    "        refer_structure['source'] = refer.xpath(\"//ref[@id=\\\"{}\\\"]//source\".format(id))[0].text\n",
    "    except:\n",
    "        refer_structure['source'] = ''\n",
    "    try:\n",
    "        refer_structure['year'] = refer.xpath(\"//ref[@id=\\\"{}\\\"]//year\".format(id))[0].text\n",
    "    except:\n",
    "        refer_structure['year'] = ''\n",
    "\n",
    "    references.append(refer_structure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.5 识别正文中的参考文献信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = [reference['id'] for reference in references]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sections = []\n",
    "\n",
    "body = root.xpath('//body')[0]\n",
    "num_sections = len(body)\n",
    "\n",
    "if num_sections > 0:\n",
    "    for sec in body:\n",
    "        try:\n",
    "            title = sec[0]\n",
    "            sec_name = title.text\n",
    "            refer_lists = []\n",
    "            p_list = sec.xpath(\".//p\")\n",
    "            for p in p_list:\n",
    "                sec_content = etree.tostring(p).decode('utf-8')\n",
    "                for refer in ids:\n",
    "                    if refer in sec_content:\n",
    "                        refer_lists.append(refer)\n",
    "            sections.append({\n",
    "                'name': sec_name,\n",
    "                'refer': refer_lists\n",
    "            })\n",
    "        except:\n",
    "            print(\"The structure is unstandard\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "refers = []\n",
    "for sec in sections:\n",
    "    refers.extend(sec['refer'])\n",
    "\n",
    "len(set(refers)) == len(ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.6 检查遗漏情况"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pbio.0000001', 'pbio.0000002']\n",
      "362279\n",
      "362279\n"
     ]
    }
   ],
   "source": [
    "filename_simple = [filename.split('.')[-3]+'.'+filename.split('.')[-2] for filename in filenames]\n",
    "print(filename_simple[:2])\n",
    "print(len(filename_simple))\n",
    "print(len(set(filename_simple)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0000001', '0000002']\n",
      "362279\n",
      "317888\n"
     ]
    }
   ],
   "source": [
    "filename_simple = [filename.split('.')[-2] for filename in filenames]\n",
    "print(filename_simple[:2])\n",
    "print(len(filename_simple))\n",
    "print(len(set(filename_simple)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('0000002', 8), ('0000032', 8)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 找出存在重合情况的数据，删除后重新爬取\n",
    "\n",
    "name_counts = {}\n",
    "\n",
    "for name in filename_simple:\n",
    "    if name in name_counts:\n",
    "        name_counts[name] += 1\n",
    "    else:\n",
    "        name_counts[name] = 1\n",
    "\n",
    "name_counts = sorted(name_counts.items(), key=lambda x:x[1], reverse=True)\n",
    "name_counts[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25119\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "dup_names = {}\n",
    "\n",
    "for item in name_counts:\n",
    "    if item[1] == 1:\n",
    "        break\n",
    "    else:\n",
    "        dup_names[item[0]] = item[1]\n",
    "\n",
    "print(len(list(dup_names.keys())))\n",
    "\n",
    "# dup_names = json.dumps(dup_names, indent=4)\n",
    "# with open(\"duplicate_plos_ids.json\", 'w') as f:\n",
    "#     f.write(dup_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 删除重复的数据\n",
    "\n",
    "names = list(dup_names.keys())\n",
    "\n",
    "path = \"../data/plos\"\n",
    "\n",
    "print(len(os.listdir(path)))\n",
    "\n",
    "for name in names:\n",
    "    os.remove(os.path.join(path, name+'.json'))\n",
    "\n",
    "print(len(os.listdir(path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 重命名非重复数据\n",
    "path = \"../data/plos\"\n",
    "\n",
    "old_names = filename_simple\n",
    "new_names = [filename.split('.')[-3]+'.'+filename.split('.')[-2] for filename in filenames]\n",
    "\n",
    "old_to_new = {old:new for old, new in zip(old_names, new_names)}\n",
    "\n",
    "for name in old_names:\n",
    "    old_file = name+\".json\"\n",
    "    new_file = old_to_new[name]+\".json\"\n",
    "\n",
    "    if os.path.exists(os.path.join(path, old_file)):\n",
    "        os.rename(os.path.join(path, old_file), os.path.join(path, new_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.7 对数据进行过滤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "317193"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 基于参考文献的研究，肯定要将reference字段为空的数据去除掉  （section为空的可能也要去掉）\n",
    "# 基于mesh词的研究，肯定要将mesh字段为空的数据去除掉\n",
    "\n",
    "# 分析reference为空的和mesh为空的论文公共子集的大小\n",
    "import os\n",
    "\n",
    "files_1 = os.listdir(\"../../data/plos\")\n",
    "files_2 = os.listdir(\"../../data/plos_mesh/\")\n",
    "\n",
    "share_files = set(files_1) & set(files_2)\n",
    "len(share_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. 描述性统计"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.1 统计每一年论文的数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ppub': '2003', 'epub': '2003'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open('../../data/plos_pub_year.json', 'r') as f:\n",
    "    pub_year = json.load(f)\n",
    "\n",
    "dois = list(pub_year.keys())\n",
    "pub_year[dois[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "362277"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dois)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "330965"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('../Data/plos_refer_doi_to_name.json') as f:\n",
    "    doi_to_name = json.load(f)\n",
    "\n",
    "name_to_doi = {v:k for k, v in doi_to_name.items()}\n",
    "len(doi_to_name.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "317191\n"
     ]
    }
   ],
   "source": [
    "year_to_cnt = {}\n",
    "miss_year_dois = []\n",
    "\n",
    "cnt = 0\n",
    "for doi in dois:\n",
    "    try:\n",
    "        if doi_to_name[doi] in share_files:\n",
    "            try:\n",
    "                year = int(pub_year[doi]['ppub'])\n",
    "            except:\n",
    "                try:\n",
    "                    year = int(pub_year[doi]['epub'])\n",
    "                except:\n",
    "                    miss_year_dois.append(year)\n",
    "                    continue\n",
    "\n",
    "            if year in year_to_cnt:\n",
    "                year_to_cnt[year] += 1\n",
    "            else:\n",
    "                year_to_cnt[year] = 1\n",
    "            cnt += 1\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "print(cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.2 统计出现频次最高的十种期刊"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3 统计出现频次最高的十种Mesh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.4 统计章节名情况，归一化篇章名"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "似乎不需要归一化篇章名，目前只要做到判断某几个参考文献是在同一章节中出现即可，无需确定章节名字"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
