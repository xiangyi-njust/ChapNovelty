{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 对CalNovelty得分结果的汇总"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### uzzi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "312124"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '../CalNovelty/refer/Result/fast_uzzi/reference'\n",
    "files = os.listdir(path)\n",
    "\n",
    "paper_to_novelty = {}\n",
    "for file in files:\n",
    "    with open(os.path.join(path, file), 'r') as f:\n",
    "        datas = json.load(f)\n",
    "\n",
    "    for data in datas:\n",
    "        paper_to_novelty[data['doi']] = {\n",
    "            'novelty':data['reference_uzzi']['score']['novelty'],\n",
    "            'year': data['year']\n",
    "        }\n",
    "\n",
    "len(paper_to_novelty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['Doi'] = list(paper_to_novelty.keys())\n",
    "df['Novelty'] = [data['novelty'] for data in paper_to_novelty.values()]\n",
    "df['Year'] = [data['year'] for data in paper_to_novelty.values()]\n",
    "df = df.dropna()\n",
    "df.to_csv(\"base_data/overview/uzzi.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 去除异常值\n",
    "Q1, Q3 = df['Novelty'].quantile([0.25, 0.75])\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "filtered_df = df[(df['Novelty'] >= Q1 - 1.5 * IQR) & (df['Novelty'] <= Q3 + 1.5 * IQR)]\n",
    "filtered_df_stats = filtered_df[['Novelty']].describe()\n",
    "filtered_df.to_csv(\"data/overview/uzzi_filtered.csv\", index=False)\n",
    "print(filtered_df_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### uzzi-sec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有两种方式去将结果利用起来\n",
    "\n",
    "    （1） 获取所有组合的分数，然后取10分位数   --具体取第几分位数，这个可以再讨论\n",
    "    （2） 将论文中不同篇章的分数取平均值，或者直接加和"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../CalNovelty/refer/Result/fast_uzzi_sec/reference'\n",
    "\n",
    "paper_to_novelty = {}\n",
    "files = os.listdir(path)\n",
    "for file in tqdm(files):\n",
    "    with open(os.path.join(path, file), 'r') as f:\n",
    "        datas = json.load(f)\n",
    "        \n",
    "    for data in datas:\n",
    "        doi = data['doi']\n",
    "        pos = doi.find('_')\n",
    "        doi = doi[:pos]\n",
    "        if doi not in paper_to_novelty:\n",
    "            paper_to_novelty[doi] = {\n",
    "                'comb_array':[],\n",
    "                'sec_novel':[]\n",
    "            }\n",
    "        paper_to_novelty[doi]['comb_array'].extend(data['reference_uzzi']['scores_array'])\n",
    "        paper_to_novelty[doi]['sec_novel'].append(data['reference_uzzi']['score']['novelty'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_to_novelty_merge_comb = {}\n",
    "paper_to_novelty_merge_sec = {}\n",
    "for doi in tqdm(paper_to_novelty):\n",
    "    paper_to_novelty_merge_comb[doi] = np.nanquantile(paper_to_novelty[doi]['comb_array'], 0.1)\n",
    "    paper_to_novelty_merge_sec[doi] = np.nanmean(paper_to_novelty[doi]['sec_novel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['Doi'] = list(paper_to_novelty_merge_comb.keys())\n",
    "df['Novelty'] = list(paper_to_novelty_merge_comb.values())\n",
    "print(len(df))\n",
    "df = df.dropna()\n",
    "df.to_csv(\"data/overview/uzzi_sec_merge_comb.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/overview/uzzi_sec_merge_sec.csv\")\n",
    "Q1, Q3 = df['Novelty'].quantile([0.25, 0.75])\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "filtered_df = df[(df['Novelty'] >= Q1 - 1.5 * IQR) & (df['Novelty'] <= Q3 + 1.5 * IQR)]\n",
    "filtered_df.to_csv(\"data/overview/uzzi_sec_merge_sec_filtered.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 添加时间因素\n",
    "with open('../../data/plos_pub_year.json', 'r') as f:\n",
    "    pub_year = json.load(f)\n",
    "\n",
    "df = pd.read_csv('base_data/overview/uzzi_sec_merge_sec_filtered.csv')\n",
    "unmatch_ids = []\n",
    "for i, idx in enumerate(df.iterrows()):\n",
    "    if idx[1]['Doi'] not in pub_year.keys():\n",
    "        unmatch_ids.append(idx[1]['Doi'])\n",
    "filter_df = df[~df['Doi'].isin(unmatch_ids)]\n",
    "\n",
    "dois = filter_df['Doi'].tolist()\n",
    "years = [pub_year[doi]['epub'] for doi in dois]\n",
    "filter_df['Year'] = years\n",
    "filter_df.to_csv('base_data/overview/uzzi_sec_merge_sec_filtered.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### wang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:00<00:00, 28.83it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "275598"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '../CalNovelty/refer/Result/fast_wang/reference'\n",
    "files = os.listdir(path)\n",
    "\n",
    "paper_to_novelty = {}\n",
    "for file in tqdm(files):\n",
    "    with open(os.path.join(path, file), 'r') as f:\n",
    "        datas = json.load(f)\n",
    "\n",
    "    for data in datas:\n",
    "        paper_to_novelty[data] = datas[data]\n",
    "\n",
    "len(paper_to_novelty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['Doi'] = list(paper_to_novelty.keys())\n",
    "df['Novelty'] = list(paper_to_novelty.values())\n",
    "df = df.dropna()\n",
    "df.to_csv(\"base_data/overview/wang.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1, Q3 = df['Novelty'].quantile([0.25, 0.75])\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "filtered_df = df[(df['Novelty'] >= Q1 - 1.5 * IQR) & (df['Novelty'] <= Q3 + 1.5 * IQR)]\n",
    "filtered_df_stats = filtered_df[['Novelty']].describe()\n",
    "filtered_df.to_csv(\"data/overview/wang_filtered.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../data/plos_pub_year.json', 'r') as f:\n",
    "    pub_year = json.load(f)\n",
    "\n",
    "df = pd.read_csv('base_data/overview/wang.csv')\n",
    "unmatch_ids = []\n",
    "for i, idx in enumerate(df.iterrows()):\n",
    "    if idx[1]['Doi'] not in pub_year.keys():\n",
    "        unmatch_ids.append(idx[1]['Doi'])\n",
    "filter_df = df[~df['Doi'].isin(unmatch_ids)]\n",
    "\n",
    "dois = filter_df['Doi'].tolist()\n",
    "years = [pub_year[doi]['epub'] for doi in dois]\n",
    "filter_df['Year'] = years\n",
    "filter_df.to_csv('base_data/overview/wang.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### wang-sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../CalNovelty/refer/Result/fast_wang_sec/reference'\n",
    "\n",
    "paper_to_novelty = {}\n",
    "files = os.listdir(path)\n",
    "for file in tqdm(files):\n",
    "    with open(os.path.join(path, file), 'r') as f:\n",
    "        datas = json.load(f)\n",
    "        \n",
    "    for data in datas:\n",
    "        doi = data\n",
    "        pos = doi.find('_')\n",
    "        doi = doi[:pos]\n",
    "        if doi not in paper_to_novelty:\n",
    "            paper_to_novelty[doi] = 0\n",
    "        paper_to_novelty[doi] = datas[data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['Doi'] = list(paper_to_novelty.keys())\n",
    "df['Novelty'] = list(paper_to_novelty.values())\n",
    "df = df.dropna()\n",
    "df_stats = df[['Novelty']].describe()\n",
    "df.to_csv(\"data/overview/wang_sec.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/overview/wang_sec.csv\")\n",
    "Q1, Q3 = df['Novelty'].quantile([0.25, 0.75])\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "filtered_df = df[(df['Novelty'] >= Q1 - 1.5 * IQR) & (df['Novelty'] <= Q3 + 1.5 * IQR)]\n",
    "filtered_df_stats = filtered_df[['Novelty']].describe()\n",
    "filtered_df.to_csv(\"data/overview/wang_sec_filtered.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../data/plos_pub_year.json', 'r') as f:\n",
    "    pub_year = json.load(f)\n",
    "\n",
    "df = pd.read_csv('base_data/overview/wang_sec.csv')\n",
    "unmatch_ids = []\n",
    "for i, idx in enumerate(df.iterrows()):\n",
    "    if idx[1]['Doi'] not in pub_year.keys():\n",
    "        unmatch_ids.append(idx[1]['Doi'])\n",
    "filter_df = df[~df['Doi'].isin(unmatch_ids)]\n",
    "\n",
    "dois = filter_df['Doi'].tolist()\n",
    "years = [pub_year[doi]['epub'] for doi in dois]\n",
    "filter_df['Year'] = years\n",
    "filter_df.to_csv('base_data/overview/wang_sec.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 合并F1000数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"gold_standard/F1000/PLos Other/\"\n",
    "files = os.listdir(file_path)\n",
    "\n",
    "df_other = pd.DataFrame()\n",
    "for file in files:\n",
    "    df = pd.read_csv(os.path.join(file_path, file))\n",
    "    df = df[['title', 'doi', 'classifications']]\n",
    "    if df_other.empty:\n",
    "        df_other = df\n",
    "    else:\n",
    "        df_other = df_other.append(df)\n",
    "\n",
    "df_other = df_other.dropna()\n",
    "len(df_other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_recom_label = ['confirmation','controversial','good for teaching','hypothesis','negative','new finding','novel drug target', 'refutation', 'technical advance']\n",
    "\n",
    "format_labels = [[] for i in range(len(standard_recom_label))]\n",
    "labels = df_other['classifications'].tolist()\n",
    "titles = df_other['title'].tolist()\n",
    "dois = df_other['doi'].tolist()\n",
    "\n",
    "new_titles, new_dois = [] ,[]\n",
    "for i, doi in enumerate(dois):\n",
    "    pos = i\n",
    "    if doi not in new_dois:\n",
    "        new_dois.append(doi)\n",
    "        new_titles.append(titles[i])\n",
    "    else:\n",
    "        pos = new_dois.index(doi)\n",
    "\n",
    "    label = labels[i].lower()  \n",
    "\n",
    "    if i != pos:\n",
    "        for j, standard_label in enumerate(standard_recom_label):\n",
    "            if standard_label in label.lower():\n",
    "                format_labels[j][pos] += 1\n",
    "    else:\n",
    "        for j, standard_label in enumerate(standard_recom_label):\n",
    "            if standard_label in label.lower():\n",
    "                format_labels[j].append(1)\n",
    "            else:\n",
    "                format_labels[j].append(0)\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['Doi'] = new_dois\n",
    "for i, standard_label in enumerate(standard_recom_label):\n",
    "    df[standard_label] = format_labels[i]\n",
    "\n",
    "df.to_excel(\"gold_standard/F1000/PLos Other/pb_all_tags.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_100 = pd.read_csv(\"gold_standard/F1000/PLos 100/plos_100_tags.csv\")\n",
    "df_bio = pd.read_excel(\"gold_standard/F1000/PLos Biology/pb_all_tags.xlsx\")\n",
    "df = pd.read_excel(\"gold_standard/F1000/PLos Other/pb_all_tags.xlsx\")\n",
    "\n",
    "select_columns = ['Doi']\n",
    "standard_recom_label = ['confirmation','controversial','good for teaching','hypothesis',\n",
    "                        'negative','new finding','novel drug target', 'refutation', 'technical advance']\n",
    "select_columns.extend(standard_recom_label)\n",
    "\n",
    "df_100 = df_100[select_columns]\n",
    "df_bio = df_bio[select_columns]\n",
    "df = df[select_columns]\n",
    "\n",
    "df_all = pd.concat([df_100, df_bio, df], axis=0, ignore_index=True)\n",
    "df_all = df_all.drop_duplicates(ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = df_all.dropna()\n",
    "\n",
    "dois = df_all['Doi'].tolist()\n",
    "formatted_dois = []\n",
    "for doi in dois:\n",
    "    if 'https://doi.org' in doi:\n",
    "        doi = doi.replace('https://doi.org/', '')\n",
    "    formatted_dois.append(doi)\n",
    "\n",
    "df_all['Doi'] = formatted_dois\n",
    "df_all = df_all.drop_duplicates(ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [df_all[standard_label].tolist() for standard_label in standard_recom_label]\n",
    "\n",
    "unique_datas = {}\n",
    "formatted_dois = df_all['Doi'].tolist()\n",
    "for i, doi in enumerate(formatted_dois):\n",
    "    if doi not in unique_datas:\n",
    "        unique_datas[doi] = {standard_label: labels[j][i] for j, standard_label in enumerate(standard_recom_label)}\n",
    "    else:\n",
    "        for j, standard_label in enumerate(standard_recom_label):\n",
    "            if labels[j][i] != 0:\n",
    "                unique_datas[doi][standard_label] = labels[j][i]\n",
    "\n",
    "format_labels = [[] for i in range(len(standard_recom_label))]\n",
    "dois = list(unique_datas.keys())\n",
    "for doi in unique_datas:\n",
    "    labels = unique_datas[doi]\n",
    "    for i, label in enumerate(labels):\n",
    "        format_labels[i].append(labels[label])\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['Doi'] = dois\n",
    "for label in standard_recom_label:\n",
    "    df[label] = format_labels[standard_recom_label.index(label)]\n",
    "df.to_excel('gold_standard/F1000/Plos_recom_tags.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../../data/plos_pub_year.json', 'r') as f:\n",
    "    pub_year = json.load(f)\n",
    "\n",
    "df = pd.read_excel('gold_standard/F1000/Plos_recom_tags.xlsx')\n",
    "unmatch_ids = []\n",
    "for i, idx in enumerate(df.iterrows()):\n",
    "    if idx[1]['Doi'] not in pub_year.keys():\n",
    "        unmatch_ids.append(idx[1]['Doi'])\n",
    "filter_df = df[~df['Doi'].isin(unmatch_ids)]\n",
    "\n",
    "dois = filter_df['Doi'].tolist()\n",
    "years = [pub_year[doi]['epub'] for doi in dois]\n",
    "filter_df['Year'] = years\n",
    "filter_df.to_excel('gold_standard/F1000/Plos_recom_tags.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
